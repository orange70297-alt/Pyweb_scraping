{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e70b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting lxml\n",
      "  Downloading lxml-6.0.2-cp314-cp314-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4->bs4)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading lxml-6.0.2-cp314-cp314-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.1 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 11.4 MB/s  0:00:00\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: typing-extensions, soupsieve, lxml, beautifulsoup4, bs4\n",
      "\n",
      "   ---------------- ----------------------- 2/5 [lxml]\n",
      "   ---------------- ----------------------- 2/5 [lxml]\n",
      "   ------------------------ --------------- 3/5 [beautifulsoup4]\n",
      "   ---------------------------------------- 5/5 [bs4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.14.2 bs4-0.0.2 lxml-6.0.2 soupsieve-2.8 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2930898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入套件\n",
    "from bs4 import BeautifulSoup as bs  \n",
    "\n",
    "# HTML elements\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<h1>Welcome</h1>\n",
    "<p class=\"title\"><b>The Chainsaw Man's anime</b></p>\n",
    "<a href=\"http://example.com/Pochita\" class=\"character\" id=\"link1\">Pochita</a>\n",
    "<a href=\"http://example.com/Power\" class=\"character\" id=\"link2\">Power</a>\n",
    "<a href=\"http://example.com/Makima\" id=\"link3\">Makima</a>\n",
    "<p class=\"anime\">They are partners in the story</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# 使用 Beautifule Soup\n",
    "\n",
    "soup = bs(html_doc,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ad85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"character\" href=\"http://example.com/Pochita\" id=\"link1\">Pochita</a>, <a class=\"character\" href=\"http://example.com/Power\" id=\"link2\">Power</a>, <a class=\"character\" href=\"http://example.com/Makima\" id=\"link3\">Makima</a>]\n",
      "<a class=\"character\" href=\"http://example.com/Pochita\" id=\"link1\">Pochita</a>\n",
      "<a class=\"character\" href=\"http://example.com/Power\" id=\"link2\">Power</a>\n",
      "<a class=\"character\" href=\"http://example.com/Makima\" id=\"link3\">Makima</a>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的 a 標籤的元素\n",
    "elements = soup.find_all('a')\n",
    "print(elements)\n",
    "for ele in elements:\n",
    "    print(ele)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c7886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"character\" href=\"http://example.com/Pochita\" id=\"link1\">Pochita</a>, <a class=\"character\" href=\"http://example.com/Power\" id=\"link2\">Power</a>, <a class=\"character\" href=\"http://example.com/Makima\" id=\"link3\">Makima</a>]\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的 a 標籤，並且 class 為 character 的元素\n",
    "elements =soup.find_all('a', class_= 'character')\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "485661b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"character\" href=\"http://example.com/Power\" id=\"link2\">Power</a>\n",
      "[<a class=\"character\" href=\"http://example.com/Pochita\" id=\"link1\">Pochita</a>]\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的 a 標籤，並且 id 為 link2 的元素\n",
    "elements = soup.find('a', id= 'link2')\n",
    "print(elements)\n",
    "\n",
    "# 找到第一個 a 標籤而且 href 為 http://example.com/Pochita 的元素\n",
    "\n",
    "elements = soup.find_all('a', href='http://example.com/Pochita')\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pochita']\n",
      "<a class=\"character\" href=\"http://example.com/Pochita\" id=\"link1\">Pochita</a>\n",
      "http://example.com/Pochita\n"
     ]
    }
   ],
   "source": [
    "# 找到所有內容為 Pochita 的元素\n",
    "elements = soup.find_all(string='Pochita')\n",
    "print(elements)\n",
    "# 取得父元素的 href 屬性值 , 因為上面使用find_all 代表抓出來的元素可能有多個波及塔\n",
    "print(elements[0].parent) # 所以打印資料出來時要加上[0] 索引第1個出現的元素\n",
    "# 透過 string 找到的元素，可以使用 parent 屬性找到其父元素\n",
    "print(elements[0].parent['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea29b54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"title\"><b>The Chainsaw Man's anime</b></p>, <p class=\"anime\">They are partners in the story</p>]\n",
      "[<p class=\"title\"><b>The Chainsaw Man's anime</b></p>]\n"
     ]
    }
   ],
   "source": [
    "# 找到所有的 p 標籤\n",
    "elements = soup.find_all('p')\n",
    "print(elements)\n",
    "\n",
    "# 找到 class=title 的 p 標籤\n",
    "\n",
    "elements = soup.find_all('p', class_='title')\n",
    "print(elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0799798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"character\" href=\"http://example.com/Power\" id=\"link2\">Power</a>]\n",
      "[<a class=\"character\" href=\"http://example.com/Power\" id=\"link2\">Power</a>]\n",
      "http://example.com/Power\n"
     ]
    }
   ],
   "source": [
    "# 找到網址為 Power 的 a 標籤\n",
    "elements = soup.find_all('a',href='http://example.com/Power')\n",
    "print(elements)\n",
    "\n",
    "\n",
    "# 找到內文為 Power 的 a 標籤\n",
    "\n",
    "elements = soup.find_all('a', string='Power')\n",
    "print(elements)\n",
    "print(elements[0]['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3864fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"character\" href=\"http://example.com/Pochita\" id=\"link1\">Pochita</a>]\n"
     ]
    }
   ],
   "source": [
    "# attribute 多條件篩選 \n",
    "elements = soup.find_all('a',{'class':'character','id':'link1'})\n",
    "print(elements)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5a0bf",
   "metadata": {},
   "source": [
    "### 使用 CSS select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入套件\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# HTML elements\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "<body>\n",
    "<h1>Welcome</h1>\n",
    "<p class=\"title\"><b>The Chainsaw Man's anime</b></p>\n",
    "<a href=\"http://example.com/Pochita\" class=\"character\" id=\"link1\">Pochita</a>\n",
    "<a href=\"http://example.com/Power\" class=\"character\" id=\"link2\">Power</a>\n",
    "<a href=\"http://example.com/Makima\" class=\"character\" id=\"link3\">Makima</a>\n",
    "<p class=\"anime\">They are partners in the story</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f7aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Beautifule Soup\n",
    "soup = bs(html_doc, 'lxml')\n",
    "\n",
    "# 使用 CSS select 找到所有的 a 標籤的元素\n",
    "\n",
    "\n",
    "# 使用 CSS select 找到所有的 a 標籤，並且 class 為 character 的元素\n",
    "\n",
    "\n",
    "# 使用 CSS select 找到所有的 a 標籤，並且 id 為 link2 的元素\n",
    "\n",
    "\n",
    "# 使用 CSS select 找到連結為 Pochita 的元素\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c181c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模糊搜尋 href 屬性中包含 Power 的元素\n",
    "\n",
    "\n",
    "# 模糊搜尋 class 結尾為 ter 的元素\n",
    "\n",
    "\n",
    "# 模糊搜尋 id 包含 link 的元素\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
